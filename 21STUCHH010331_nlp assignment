{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["**Import Libraries and Download NLTK Data**"],"metadata":{"id":"ddtuxo903LLf"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1cx5h4jl3E5T","executionInfo":{"status":"ok","timestamp":1729443879470,"user_tz":-330,"elapsed":5764,"user":{"displayName":"Varshith Varma","userId":"15931589040788364322"}},"outputId":"62417759-fa78-4287-ffa8-6580a0443274"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":1}],"source":["# Import necessary libraries for text preprocessing and sentiment analysis\n","import nltk\n","import pandas as pd\n","from nltk.corpus import stopwords\n","from nltk.stem import WordNetLemmatizer\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.model_selection import train_test_split\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.metrics import accuracy_score\n","\n","# Download necessary NLTK data (this step is needed only once)\n","nltk.download('stopwords')  # Common words like 'the', 'is', etc.\n","nltk.download('wordnet')  # For lemmatization (reducing words to their root form)\n","nltk.download('punkt')  # For tokenization (splitting sentences into words)"]},{"cell_type":"markdown","source":["**Create a New Sample Dataset**"],"metadata":{"id":"Wg0css2Z3g1C"}},{"cell_type":"code","source":["# Create a sample dataset with diverse reviews and their corresponding sentiments\n","data = {\n","    'review': [\n","        \"The food was excellent, and the service was fast and friendly.\",\n","        \"I had a terrible experience, the waiter was rude.\",\n","        \"The movie was a bit too long, but the visuals were stunning.\",\n","        \"This laptop exceeded my expectations, great performance!\",\n","        \"The flight was delayed for hours, very frustrating.\",\n","        \"Amazing customer support! They solved my issue in minutes.\",\n","        \"The coffee was cold, and the place was too noisy.\",\n","        \"I'm impressed with the camera quality on this phone.\",\n","        \"The product stopped working after a week. Very disappointing.\",\n","        \"Beautiful hotel with clean rooms and great amenities.\"\n","    ],\n","    'sentiment': [1, 0, 0, 1, 0, 1, 0, 1, 0, 1]\n","}\n","\n","# Convert the dataset into a DataFrame for easy handling\n","df = pd.DataFrame(data)\n","print(\"Sample Data:\\n\", df.head())\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ex_AhQzQ3qRg","executionInfo":{"status":"ok","timestamp":1729443879471,"user_tz":-330,"elapsed":9,"user":{"displayName":"Varshith Varma","userId":"15931589040788364322"}},"outputId":"6551e046-1404-4de7-fe91-f72caf7ef716"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Sample Data:\n","                                               review  sentiment\n","0  The food was excellent, and the service was fa...          1\n","1  I had a terrible experience, the waiter was rude.          0\n","2  The movie was a bit too long, but the visuals ...          0\n","3  This laptop exceeded my expectations, great pe...          1\n","4  The flight was delayed for hours, very frustra...          0\n"]}]},{"cell_type":"markdown","source":["**Preprocess the Reviews**"],"metadata":{"id":"8qYXf_VB3w1h"}},{"cell_type":"code","source":["# Define a function to preprocess the text (remove stopwords, lemmatize, etc.)\n","def preprocess_text(text):\n","    # Tokenize the text (split it into words)\n","    words = nltk.word_tokenize(text.lower())  # Convert to lowercase to avoid case mismatches\n","\n","    # Load English stopwords (common words like 'the', 'is', etc.)\n","    stop_words = set(stopwords.words('english'))\n","\n","    # Filter out stopwords and non-alphabetic words\n","    filtered_words = [word for word in words if word.isalpha() and word not in stop_words]\n","\n","    # Initialize the lemmatizer to reduce words to their base form\n","    lemmatizer = WordNetLemmatizer()\n","    lemmatized_words = [lemmatizer.lemmatize(word) for word in filtered_words]\n","\n","    # Join the words back into a single string\n","    return ' '.join(lemmatized_words)\n","\n","# Apply the preprocessing function to the 'review' column in the DataFrame\n","df['cleaned_review'] = df['review'].apply(preprocess_text)\n","print(\"Preprocessed Data:\\n\", df[['review', 'cleaned_review']])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"deSjlTkM315E","executionInfo":{"status":"ok","timestamp":1729443881600,"user_tz":-330,"elapsed":2136,"user":{"displayName":"Varshith Varma","userId":"15931589040788364322"}},"outputId":"826eb8b4-3175-498d-df82-a8289ed6d9b4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Preprocessed Data:\n","                                               review  \\\n","0  The food was excellent, and the service was fa...   \n","1  I had a terrible experience, the waiter was rude.   \n","2  The movie was a bit too long, but the visuals ...   \n","3  This laptop exceeded my expectations, great pe...   \n","4  The flight was delayed for hours, very frustra...   \n","5  Amazing customer support! They solved my issue...   \n","6  The coffee was cold, and the place was too noisy.   \n","7  I'm impressed with the camera quality on this ...   \n","8  The product stopped working after a week. Very...   \n","9  Beautiful hotel with clean rooms and great ame...   \n","\n","                                  cleaned_review  \n","0           food excellent service fast friendly  \n","1                terrible experience waiter rude  \n","2                movie bit long visuals stunning  \n","3  laptop exceeded expectation great performance  \n","4                flight delayed hour frustrating  \n","5   amazing customer support solved issue minute  \n","6                        coffee cold place noisy  \n","7                 impressed camera quality phone  \n","8     product stopped working week disappointing  \n","9       beautiful hotel clean room great amenity  \n"]}]},{"cell_type":"markdown","source":["**Convert Text Data to Bag-of-Words (CountVectorizer)**"],"metadata":{"id":"_6cbZkqP348d"}},{"cell_type":"code","source":["# Define the feature (X) and label (y)\n","X = df['cleaned_review']  # The cleaned reviews\n","y = df['sentiment']  # The corresponding sentiment (1 = positive, 0 = negative)\n","\n","# Initialize a CountVectorizer to convert text into a matrix of token counts\n","vectorizer = CountVectorizer()\n","\n","# Fit the vectorizer on the text data and transform it into numerical form\n","X_vectorized = vectorizer.fit_transform(X)\n","\n","print(\"Feature Matrix Shape:\", X_vectorized.shape)  # Check the size of the matrix\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pnOqZLal389g","executionInfo":{"status":"ok","timestamp":1729443881600,"user_tz":-330,"elapsed":38,"user":{"displayName":"Varshith Varma","userId":"15931589040788364322"}},"outputId":"24cff308-db29-44d6-9b82-812feef3eec9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Feature Matrix Shape: (10, 47)\n"]}]},{"cell_type":"markdown","source":["**Split the Data into Training and Testing Sets**"],"metadata":{"id":"H7bt-ps34Al3"}},{"cell_type":"code","source":["# Split the data into 80% training and 20% testing\n","X_train, X_test, y_train, y_test = train_test_split(X_vectorized, y, test_size=0.2, random_state=42)\n","\n","print(\"Training Data Size:\", X_train.shape)\n","print(\"Testing Data Size:\", X_test.shape)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bTPmpU6N4ESq","executionInfo":{"status":"ok","timestamp":1729443881601,"user_tz":-330,"elapsed":38,"user":{"displayName":"Varshith Varma","userId":"15931589040788364322"}},"outputId":"76f01e72-7151-43ed-f744-49f533bda444"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training Data Size: (8, 47)\n","Testing Data Size: (2, 47)\n"]}]},{"cell_type":"markdown","source":["**Train the Naive Bayes Model**"],"metadata":{"id":"cSbG3DqJ4GtG"}},{"cell_type":"code","source":["# Initialize a Naive Bayes classifier\n","model = MultinomialNB()\n","\n","# Train the model using the training data\n","model.fit(X_train, y_train)\n","\n","print(\"Model training completed.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zYwtXbGN4GN9","executionInfo":{"status":"ok","timestamp":1729443881601,"user_tz":-330,"elapsed":35,"user":{"displayName":"Varshith Varma","userId":"15931589040788364322"}},"outputId":"f59f5544-291b-47f5-a230-25eea61b7e2d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model training completed.\n"]}]},{"cell_type":"markdown","source":["**Evaluate the Model on the Test Set**"],"metadata":{"id":"NEA-tKYg4MH3"}},{"cell_type":"code","source":["# Predict the sentiment of the test reviews\n","y_pred = model.predict(X_test)\n","\n","# Calculate the accuracy of the model\n","accuracy = accuracy_score(y_test, y_pred)\n","print(f\"Model Accuracy: {accuracy * 100:.2f}%\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xoom-edj4ULb","executionInfo":{"status":"ok","timestamp":1729443881602,"user_tz":-330,"elapsed":33,"user":{"displayName":"Varshith Varma","userId":"15931589040788364322"}},"outputId":"a4751f5b-e2a6-4829-d9a7-6c8ca4d6776d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model Accuracy: 100.00%\n"]}]},{"cell_type":"markdown","source":["**Analyze a New User-Input Review**\n"],"metadata":{"id":"gFqytddu4WJy"}},{"cell_type":"code","source":["# Function to classify a new review entered by the user\n","def analyze_user_review():\n","    # Ask the user to input a review\n","    user_review = input(\"Enter a review: \")\n","\n","    # Preprocess the review using the same steps\n","    preprocessed_review = preprocess_text(user_review)\n","\n","    # Convert the preprocessed review to vector form\n","    review_vectorized = vectorizer.transform([preprocessed_review])\n","\n","    # Predict the sentiment of the review (1 = positive, 0 = negative)\n","    prediction = model.predict(review_vectorized)[0]\n","\n","    # Print the result\n","    if prediction == 1:\n","        print(\"The review is positive.\")\n","    else:\n","        print(\"The review is negative.\")\n","\n","# Call the function to allow the user to enter a review\n","analyze_user_review()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"doRUrptB4dMI","executionInfo":{"status":"ok","timestamp":1729443940230,"user_tz":-330,"elapsed":8976,"user":{"displayName":"Varshith Varma","userId":"15931589040788364322"}},"outputId":"ca50b6a5-6d29-42a7-c36b-2bae40557393"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Enter a review: \"The food was excellent, and the service was fast and friendly.\"\n","The review is positive.\n"]}]}]}